print(paste('Logistic Regression Accuracy is ', 1-misClasificError))
fitted.results <- predict(newModel,newdata=testing_data,type='response')
fitted.results <- ifelse(fitted.results > 0.27,1,0)
misClasificError <- mean(fitted.results != testing_data$Churn)
misClasificError
print(paste('Logistic Regression Accuracy is ', 1-misClasificError))
testing_data$pred <- fitted.results
testing_data%>%
group_by(pred) %>%
select(TotalCharges, MonthlyCharges, tenure) %>%
summarise_all(funs(mean(.)))
testing_data$pred <- fitted.results
testing_data%>%
group_by(pred) %>%
dplyr::select(TotalCharges, MonthlyCharges, tenure) %>%
summarise_all(funs(mean(.)))
knitr::opts_chunk$set(echo = TRUE)
onlineRetail <- read.csv("https://www.dropbox.com/s/zemwk29vgvgb87t/Online%20Retail.csv?dl=1")
str(onlineRetail)
library(dplyr)
library(ggplot2)
onlineRetail %>%
select(CustomerID) %>%
is.na() %>%
sum()
detach("package:MASS", unload=TRUE)
library(dplyr)
library(ggplot2)
onlineRetail %>%
select(CustomerID) %>%
is.na() %>%
sum()
onlineRetail_new <- onlineRetail %>%
filter(!is.na(CustomerID))
onlineRetail_new<-onlineRetail_new %>%
mutate(InvoiceDate=as.Date(InvoiceDate, format = "%m/%d/%y"))
range(onlineRetail_new$InvoiceDate)
onlineRetail_new <- subset(onlineRetail_new, InvoiceDate >= "2010-12-09")
range(onlineRetail_new$InvoiceDate)
table(onlineRetail_new$Country)
onlineRetail_new <- subset(onlineRetail_new, Country == "Germany")
length(unique(onlineRetail_new$InvoiceNo))
length(unique(onlineRetail_new$CustomerID))
# Identify returns
onlineRetail_new$item.return <- grepl("C", onlineRetail_new$InvoiceNo, fixed=TRUE)
onlineRetail_new$purchase.invoice <- ifelse(onlineRetail_new$item.return=="TRUE", 0, 1)
onlineRetail_new <- subset(onlineRetail_new, Country == "Germany")
length(unique(onlineRetail_new$InvoiceNo))
length(unique(onlineRetail_new$CustomerID))
# Identify returns
onlineRetail_new$item.return <- grepl("C", onlineRetail_new$InvoiceNo, fixed=TRUE)
onlineRetail_new$purchase.invoice <- ifelse(onlineRetail_new$item.return=="TRUE", 0, 1)
library(dplyr)
recency <- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
mutate(recency = as.numeric(difftime("2011-12-10", as.Date(InvoiceDate)), units="days")
)
recency <- aggregate(recency ~ CustomerID, data=recency, FUN=min, na.rm=TRUE)
library(dplyr)
frequency<- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
select("CustomerID","InvoiceNo", "purchase.invoice") %>%
arrange(CustomerID)
frequency <- aggregate(purchase.invoice ~ CustomerID, data=frequency, FUN=sum, na.rm=TRUE)
colnames(frequency)[colnames(frequency)=="purchase.invoice"] <- "frequency"
# Total spent on each item on an invoice
annual.sales <- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
mutate(Amount = Quantity*UnitPrice)
# Aggregated total sales to customer
annual.sales <- aggregate(Amount ~ CustomerID, data=annual.sales, FUN=sum, na.rm=TRUE)
names(annual.sales)[names(annual.sales)=="Amount"] <- "monetary"
# merge all three variables
customers <- left_join(recency, frequency, by="CustomerID") %>%
left_join(.,annual.sales, by="CustomerID")
hist(customers$monetary)
customers$monetary <- ifelse(customers$monetary < 0, 0, customers$monetary)
hist(customers$monetary)
library(purrr)
library(ggplot2)
library(dplyr)
# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:10,  function(k){
model <- kmeans(x = customers[,2:4], centers = k)
model$tot.withinss
})
# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
k = 1:10,
tot_withinss = tot_withinss
)
# Plot the elbow plot
ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
geom_line() +
scale_x_continuous(breaks = 1:10)
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 2)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
# Plot the positions of the players and color them using their cluster
ggplot(customers_segment, aes(x = log(recency), y = log(monetary), color = factor(cluster))) +
geom_point()
customers_segment %>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))
table(onlineRetail_new$Country)
onlineRetail_new <- subset(onlineRetail_new, Country == "United Kingdom")
length(unique(onlineRetail_new$InvoiceNo))
length(unique(onlineRetail_new$CustomerID))
onlineRetail <- read.csv("https://www.dropbox.com/s/zemwk29vgvgb87t/Online%20Retail.csv?dl=1")
str(onlineRetail)
library(dplyr)
library(ggplot2)
onlineRetail %>%
select(CustomerID) %>%
is.na() %>%
sum()
onlineRetail_new <- onlineRetail %>%
filter(!is.na(CustomerID))
onlineRetail_new<-onlineRetail_new %>%
mutate(InvoiceDate=as.Date(InvoiceDate, format = "%m/%d/%y"))
range(onlineRetail_new$InvoiceDate)
onlineRetail_new <- subset(onlineRetail_new, InvoiceDate >= "2010-12-09")
range(onlineRetail_new$InvoiceDate)
table(onlineRetail_new$Country)
onlineRetail_new <- subset(onlineRetail_new, Country == "United Kingdom")
length(unique(onlineRetail_new$InvoiceNo))
length(unique(onlineRetail_new$CustomerID))
# Identify returns
onlineRetail_new$item.return <- grepl("C", onlineRetail_new$InvoiceNo, fixed=TRUE)
onlineRetail_new$purchase.invoice <- ifelse(onlineRetail_new$item.return=="TRUE", 0, 1)
library(dplyr)
recency <- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
mutate(recency = as.numeric(difftime("2011-12-10", as.Date(InvoiceDate)), units="days")
)
recency <- aggregate(recency ~ CustomerID, data=recency, FUN=min, na.rm=TRUE)
library(dplyr)
frequency<- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
select("CustomerID","InvoiceNo", "purchase.invoice") %>%
arrange(CustomerID)
frequency <- aggregate(purchase.invoice ~ CustomerID, data=frequency, FUN=sum, na.rm=TRUE)
colnames(frequency)[colnames(frequency)=="purchase.invoice"] <- "frequency"
# Total spent on each item on an invoice
annual.sales <- onlineRetail_new %>%
filter(purchase.invoice == 1) %>%
mutate(Amount = Quantity*UnitPrice)
# Aggregated total sales to customer
annual.sales <- aggregate(Amount ~ CustomerID, data=annual.sales, FUN=sum, na.rm=TRUE)
names(annual.sales)[names(annual.sales)=="Amount"] <- "monetary"
# merge all three variables
customers <- left_join(recency, frequency, by="CustomerID") %>%
left_join(.,annual.sales, by="CustomerID")
hist(customers$monetary)
customers$monetary <- ifelse(customers$monetary < 0, 0, customers$monetary)
hist(customers$monetary)
summary(customers$monetary)
customers$monetary <- ifelse(customers$monetary < 0, 0, customers$monetary)
library(purrr)
library(ggplot2)
library(dplyr)
# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:10,  function(k){
model <- kmeans(x = customers[,2:4], centers = k)
model$tot.withinss
})
# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
k = 1:10,
tot_withinss = tot_withinss
)
# Plot the elbow plot
ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
geom_line() +
scale_x_continuous(breaks = 1:10)
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 2)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
# Plot the positions of the players and color them using their cluster
ggplot(customers_segment, aes(x = log(recency), y = log(monetary), color = factor(cluster))) +
geom_point()
customers_segment %>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 3)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
# Plot the positions of the players and color them using their cluster
ggplot(customers_segment, aes(x = log(recency), y = log(monetary), color = factor(cluster))) +
geom_point()
customers_segment %>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 2)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
# Plot the positions of the players and color them using their cluster
ggplot(customers_segment, aes(x = log(recency), y = log(monetary), color = factor(cluster))) +
geom_point()
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 2)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
customers_segment %>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))
customers_segment %>%
group_by(cluster) %>%
count()
customers_segment %>%
group_by(cluster) %>%
summarise_all(funs(mean(.)))
customers<-read.csv("https://www.dropbox.com/s/3bs78srrnjuwcmu/customers.csv?dl=1")
library(purrr)
library(car)
library(rgl)
library(dplyr)
# Plot clusters in 3D
colors <- c('red','orange','green3','deepskyblue','blue','darkorchid4','violet','pink1','tan3','black')
# Build a kmeans model
model_km <- kmeans(customers[,2:4], centers = 4)
# Extract the cluster assignment vector from the kmeans model
clust_km <- model_km$cluster
# Create a new dataframe appending the cluster assignment
customers_segment <- mutate(customers, cluster = clust_km)
scatter3d(x = log(customers_segment$frequency),
y = log(customers_segment$monetary),
z = log(customers_segment$recency),
groups = factor(customers_segment$cluster),
xlab = "Frequency (Log-transformed)",
ylab = "Monetary Value (log-transformed)",
zlab = "Recency (Log-transformed)",
surface.col = colors,
axis.scales = FALSE,
surface = TRUE, # produces the horizonal planes through the graph at each level of monetary value
fit = "smooth",
#     ellipsoid = TRUE, # to graph ellipses uses this command and set "surface = " to FALSE
grid = TRUE,
axis.col = c("black", "black", "black"))
remove(colors)
library(mgcv)
knitr::opts_chunk$set(echo = TRUE)
my_data <- read.csv("https://www.dropbox.com/s/sy790xviuxn8psp/movie_metadata.csv?dl=1")
library(dplyr)
my_data <- my_data %>%
na.omit() %>%
mutate(gross=gross/1000000, budget=budget/1000000, USA = as.numeric(country== "USA"), restricted=as.numeric(content_rating== "PG-13"|content_rating=="R"|content_rating== "NC-17")) %>%
select(-actor_1_name, -actor_2_name, -actor_3_name, -actor_2_facebook_likes,  -actor_3_facebook_likes, -movie_imdb_link, -plot_keywords, -color, -director_name, -cast_total_facebook_likes, -country, -content_rating)
library(dplyr)
my_data <- my_data %>%
filter(budget<200)
set.seed(100)
trainingRowIndex <- sample(1:nrow(my_data), 0.7*nrow(my_data))
training_data <- my_data[trainingRowIndex, ] # model training data
testing_data <- my_data[-trainingRowIndex, ] # test data
set.seed(100)
trainingRowIndex <- sample(1:nrow(my_data), 0.7*nrow(my_data))
training_data <- my_data[trainingRowIndex, ] # model training data
testing_data <- my_data[-trainingRowIndex, ] # test data
training_data
set.seed(100)
trainingRowIndex <- sample(1:nrow(my_data), 0.7*nrow(my_data))
training_data <- my_data[trainingRowIndex, ] # model training data
testing_data <- my_data[-trainingRowIndex, ] # test data
summary(training_data)
fmla <- gross ~ budget + imdb_score
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
fmla <- gross ~ budget + imdb_score + director_facebook_likes +
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
fmla <- gross ~ budget + imdb_score + director_facebook_likes
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + actor_1_facebook_likes
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
fmla <- gross ~ budget + imdb_score  + actor_1_facebook_likes
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + restricted
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
my_data <- read.csv("https://www.dropbox.com/s/sy790xviuxn8psp/movie_metadata.csv?dl=1")
library(dplyr)
my_data <- my_data %>%
na.omit() %>%
mutate(gross=gross/1000000, budget=budget/1000000, USA = as.numeric(country== "USA"), restricted=as.numeric(content_rating == content_rating== "NC-17")) %>%
my_data <- read.csv("https://www.dropbox.com/s/sy790xviuxn8psp/movie_metadata.csv?dl=1")
library(dplyr)
my_data <- my_data %>%
na.omit() %>%
mutate(gross=gross/1000000, budget=budget/1000000, USA = as.numeric(country== "USA"), restricted=as.numeric(content_rating== "NC-17")) %>%
select(-actor_1_name, -actor_2_name, -actor_3_name, -actor_2_facebook_likes,  -actor_3_facebook_likes, -movie_imdb_link, -plot_keywords, -color, -director_name, -cast_total_facebook_likes, -country, -content_rating)
library(dplyr)
my_data <- my_data %>%
filter(budget<200)
set.seed(100)
trainingRowIndex <- sample(1:nrow(my_data), 0.7*nrow(my_data))
training_data <- my_data[trainingRowIndex, ] # model training data
testing_data <- my_data[-trainingRowIndex, ] # test data
summary(training_data)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + restricted
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + restricted
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
glance(unemployment_model)
install.packages("broom")
library(broom)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + restricted
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
glance(unemployment_model)
library(broom)
fmla <- gross ~ budget + imdb_score + director_facebook_likes + restricted
# Use the formula to fit a model
movie_model <- lm(fmla, data=training_data)
summary(movie_model)
glance(movie_model)
# Predict gross income in the trainning data set
training_data$prediction <-  predict(movie_model, training_data)
# load the ggplot2 package
library(ggplot2)
# Make a plot to compare predictions to actual (prediction on x axis).
ggplot(unemployment, aes(x = prediction, y = gross)) +
geom_point() +
geom_abline(color = "blue")
# Predict gross income in the trainning data set
training_data$prediction <-  predict(movie_model, training_data)
# load the ggplot2 package
library(ggplot2)
# Make a plot to compare predictions to actual (prediction on x axis).
ggplot(movie_model, aes(x = prediction, y = gross)) +
geom_point() +
geom_abline(color = "blue")
# Predict gross income in the trainning data set
training_data$prediction <-  predict(movie_model, training_data)
# load the ggplot2 package
library(ggplot2)
# Make a plot to compare predictions to actual (prediction on x axis).
ggplot(training_data, aes(x = prediction, y = gross)) +
geom_point() +
geom_abline(color = "blue")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
# Predict gross income in the trainning data set
training_data$predictions <-  predict(movie_model, training_data)
# load the ggplot2 package
library(ggplot2)
# Make a plot to compare predictions to actual (prediction on x axis).
ggplot(training_data, aes(x = predictions, y = gross)) +
geom_point() +
geom_abline(color = "blue")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_point() +
geom_abline(color = "blue")+
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
mean(training_data$residuals)
?geom_pointrange
library("WVPlots")
install.packages("WVPlots")
library(WVPlots)
GainCurvePlot(training_data, "predictions", "gross", "movie model")
library(WVPlots)
GainCurvePlot(training_data, "gross", "predictions", "movie model")
library(WVPlots)
GainCurvePlot(training_data, "predictions", "gross", "movie model")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
res <- movie_model$residuals
mean(res)
mean(training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
View(training_data)
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
sum(training_data$residual==training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
sum(training_data$residual!=training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
mean(training_data$residual!=training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
mean(training_data$residual)
mean(training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
training_data$v<-(training_data$residual==training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
training_data$v<-(training_data$residual==training_data$residuals)
training_data$residual[1]
training_data$residuals[1]
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
# Calculate residuals
training_data$residuals <- training_data$gross - training_data$predictions
training_data$residual <- movie_model$residuals
training_data$v<-(training_data$residual==training_data$residuals)
training_data$residual[1]
training_data$residuals[1]
summary(training_data$residual)
summary(training_data$residuals)
# Fill in the blanks to plot predictions (on x-axis) versus the residuals
ggplot(training_data, aes(x = predictions, y = residuals)) +
geom_pointrange(aes(ymin = 0, ymax = residuals)) +
geom_hline(yintercept = 0, linetype = 3) +
ggtitle("residuals vs. linear model prediction")
install.packages("corrplot")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
my_data <- read.csv("https://www.dropbox.com/s/sy790xviuxn8psp/movie_metadata.csv?dl=1")
knitr::opts_chunk$set(echo = TRUE)
onlineRetail <- read.csv("https://www.dropbox.com/s/zemwk29vgvgb87t/Online%20Retail.csv?dl=1")
str(onlineRetail)
library(dplyr)
library(ggplot2)
onlineRetail %>%
select(CustomerID) %>%
is.na() %>%
sum()
onlineRetail_new <- onlineRetail %>%
filter(!is.na(CustomerID))
